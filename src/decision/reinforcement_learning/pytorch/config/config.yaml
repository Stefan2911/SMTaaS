logging-level: 10 # logging.DEBUG

hyper-parameters:
  batch-size: 64
  gamma: 0.999        # discount factor used in the Bellman equation
  eps-start: 0.9        # starting value of epsilon (epsilon = exploration rate)
  eps-end: 0.05       # ending value of epsilon
  eps-decay: 0.005    # decay rate used to decay epsilon over time
  target-update: 5    # defines how frequently (in terms of episodes), the target network weights are updated
  memory-size: 100000 # capacity of replay memory
  lr: 0.01            # learning rate
  num-episodes: 200   # number of episodes
  episode-length: 5   # number of smt problems solved in one episode

basic-reward: 1

# TODO: reward model must be defined in more detail (could be done by operator)
reward-modes:
  energy-aware:
    active: False
    ranges:
      - end: 0      # < 1 percent of battery needed
        reward: 5
      - start: 1    # 1 percent of battery needed
        end: 1
        reward: -1
      - start: 2    # >= 2 percent of battery needed
        reward: -1
  time-aware:
    active: True
    ranges:
      - end: 1.5      # < 1.5 seconds
        reward: 3
      - start: 1.5    # > 1.5 seconds
        reward: -4
  traffic-aware:
    active: False

ev3: False

